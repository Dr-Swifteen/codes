{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c01195bc",
   "metadata": {},
   "source": [
    "#### 📌 **HİPERPARAMETRELERİ BURADAN AYARLA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e86f048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3       \n",
    "batch_size = 32           \n",
    "pca_variance = 0.94       # PCA varyans koruma oranı\n",
    "roi_crop_size = (256,256)\n",
    "patch_size = (128,128)\n",
    "mlp_hidden_units = [128, 528]\n",
    "mlp_dropout_rate = 0.5\n",
    "mlp_epochs = 40\n",
    "mlp_earlystop_patience = 25\n",
    "pixels_per_cell=(16,16)\n",
    "cells_per_block=(2,2)\n",
    "orientations=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c99ec62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, joblib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import hog, greycomatrix, greycoprops\n",
    "from skimage.filters import threshold_otsu, median\n",
    "from skimage.morphology import opening, disk\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from joblib import Parallel, delayed\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b7c61",
   "metadata": {},
   "source": [
    "#### 📁 **1. Görüntü Yolu Listeleme Fonksiyonu ve Ön işleme**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "503e4d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_image(args):\n",
    "    img_path, label, classes = args\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, roi_crop_size)\n",
    "    img = img.astype(np.float32)\n",
    "\n",
    "    center = np.array(roi_crop_size) // 2\n",
    "    ps = np.array(patch_size) // 2\n",
    "    patch = img[center[0]-ps[0]:center[0]+ps[0], center[1]-ps[1]+0:center[1]+ps[1]]\n",
    "\n",
    "    patch = median(patch)\n",
    "    patch = cv2.GaussianBlur(patch, (3, 3), 0)\n",
    "    patch = patch.astype(np.float32) / 255.0\n",
    "\n",
    "    return patch, classes.index(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdac1a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_preprocess_parallel(root_dir, classes, n_jobs=-1):\n",
    "    class_dirs = {\n",
    "        'normal': ['Birad1'],\n",
    "        'benign': ['Birad3'],\n",
    "        'cancer': ['Birad4', 'Birad5'],\n",
    "    }\n",
    "    paths, labels = [], []\n",
    "    for cls, subdirs in class_dirs.items():\n",
    "        for sd in subdirs:\n",
    "            dir_path = os.path.join(root_dir, sd)\n",
    "            if not os.path.isdir(dir_path):\n",
    "                continue\n",
    "            for fname in sorted(os.listdir(dir_path)):\n",
    "                if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    paths.append(os.path.join(dir_path, fname))\n",
    "                    labels.append(cls)\n",
    "    \n",
    "\n",
    "    # === Paralel işleme ===\n",
    "    arg_list = [(img_path, lbl, classes) for img_path, lbl in zip(paths, labels)]\n",
    "    results = Parallel(n_jobs=n_jobs)(delayed(process_single_image)(args) for args in arg_list)\n",
    "\n",
    "    X, y = zip(*results)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503afa77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a467d65",
   "metadata": {},
   "source": [
    "#### 🧼 **2. ROI extraction**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dff67e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_image(im):\n",
    "    h = hog(im, pixels_per_cell=pixels_per_cell,\n",
    "                cells_per_block=cells_per_block,\n",
    "                orientations=orientations)\n",
    "    g = greycomatrix((im*255).astype(np.uint8), [1], [0], levels=256)\n",
    "    glcm = [greycoprops(g, prop)[0, 0] for prop in ('contrast', 'homogeneity', 'energy')]\n",
    "    area = np.sum(im > 0.5)\n",
    "    perimeter = np.sum(cv2.Canny((im * 255).astype(np.uint8), 50, 150) > 0)\n",
    "    ecc = 0\n",
    "    if area > 10:\n",
    "        pts = np.argwhere(im > 0.5)\n",
    "        rect = cv2.minAreaRect(pts.astype(np.float32))\n",
    "        ecc = rect[1][0] / (rect[1][1] + 1e-8)\n",
    "    return np.hstack([h, glcm, area, perimeter, ecc])\n",
    "\n",
    "def extract_features(X, out_prefix=None, n_jobs=-1):\n",
    "    # 2. UPDATE THE FUNCTION NAME INSIDE THE PARALLEL CALL HERE\n",
    "    feats = Parallel(n_jobs=n_jobs)(delayed(extract_features_from_image)(im) for im in X)\n",
    "    feats = np.array(feats)\n",
    "    pca = PCA(n_components=pca_variance)\n",
    "    X_feat = pca.fit_transform(feats)\n",
    "    return X_feat, pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4470488c",
   "metadata": {},
   "source": [
    "#### 🧠 **3. CNN Model Tanımı**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ddbdfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp_model(input_dim, num_classes, hidden_units, dropout_rate):\n",
    "    model = Sequential([\n",
    "        Dense(hidden_units[0], activation='relu', input_shape=(input_dim,)),\n",
    "        Dense(hidden_units[0], activation='relu', input_shape=(input_dim,)),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(hidden_units[1], activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ebbbaf",
   "metadata": {},
   "source": [
    "#### 🚂 **4. Model Eğitimi ve Kaydetme**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26b0f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(X_tr, X_test, y_tr, y_test,X_feat,classes):\n",
    "    \n",
    "    y_tr_cat = pd.get_dummies(y_tr).values\n",
    "    # model\n",
    "    model = create_mlp_model(\n",
    "        input_dim    = X_feat.shape[1],\n",
    "        num_classes  = len(classes),\n",
    "        hidden_units = mlp_hidden_units,\n",
    "        dropout_rate = mlp_dropout_rate\n",
    "    )\n",
    "    model.compile(optimizer=Adam(learning_rate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=mlp_earlystop_patience, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(patience=mlp_earlystop_patience//2, factor=0.5)\n",
    "    ]\n",
    "    model.fit(X_tr, y_tr_cat,\n",
    "              validation_split=0.1,\n",
    "              epochs=mlp_epochs,\n",
    "              batch_size=batch_size,\n",
    "              callbacks=callbacks,\n",
    "              verbose=1)\n",
    "    olasiliklar = model.predict(X_test)\n",
    "    esikler = np.linspace(0.4, 0.6, 21)\n",
    "    en_iyi_f1, en_iyi_T_m, en_iyi_T_b = 0, 0.47, 0.53\n",
    "    for T_m_aday in esikler:\n",
    "        for T_b_aday in esikler:\n",
    "            tahminler = [2 if p[2] >= T_m_aday else 1 if p[1] >= T_b_aday else 0 for p in olasiliklar]\n",
    "            f1 = f1_score(y_test, tahminler, average='macro')\n",
    "            if f1 > en_iyi_f1:\n",
    "                en_iyi_f1, en_iyi_T_m, en_iyi_T_b = f1, T_m_aday, T_b_aday\n",
    "    nihai_tahminler = [2 if p[2] >= en_iyi_T_m else 1 if p[1] >= en_iyi_T_b else 0 for p in olasiliklar]\n",
    "    print()\n",
    "    print(\"---------------------MLP_Results---------------------\")\n",
    "    print(f\"En iyi eşik sınırı: T_m={en_iyi_T_m:.2f}, T_b={en_iyi_T_b:.2f}\")\n",
    "    print(classification_report(y_test, nihai_tahminler, target_names=['normal','benign','cancer']))\n",
    "    print(confusion_matrix(y_test, nihai_tahminler))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, nihai_tahminler))\n",
    "    print(\"Precision:\", precision_score(y_test, nihai_tahminler, average='macro'))\n",
    "    print(\"Recall:\", recall_score(y_test, nihai_tahminler, average='macro'))\n",
    "    try:\n",
    "        print(\"AUC:\", roc_auc_score(pd.get_dummies(y_test), olasiliklar, average='macro', multi_class='ovr'))\n",
    "    except:\n",
    "        print(\"AUC hesaplanamadı (muhtemelen tek sınıf tahmini nedeniyle)\")\n",
    "\n",
    "    model_name=\"MLP_1_2\"\n",
    "    model.save(f\"{model_name}.h5\")\n",
    "    print(f\"Model kaydedildi: {model_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b12eec",
   "metadata": {},
   "source": [
    " Metirkler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c71fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec2926e8",
   "metadata": {},
   "source": [
    "#### 💾 **6. Model ve Eşik Kayıtları**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed070b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9036122",
   "metadata": {},
   "source": [
    "#### 📌 **HİPERPARAMETRELERİ BURADAN AYARLA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe92af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_estimators=300\n",
    "max_depth=50    \n",
    "random_state=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983223b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24641b4b",
   "metadata": {},
   "source": [
    "#### 🧠 **3. CNN Model Tanımı**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d362a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Forest(X_tr, X_test, y_tr, y_test,X_feat,classes):\n",
    "    \n",
    "    # model tanımı\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                   max_depth=max_depth,\n",
    "                                   random_state=random_state)\n",
    "    model.fit(X_tr, y_tr)\n",
    "    # kaydet\n",
    "    \n",
    "    \n",
    "    # değerlendirme\n",
    "    olasiliklar = model.predict_proba(X_test)\n",
    "    esikler = np.linspace(0.4, 0.6, 21)\n",
    "    en_iyi_f1, en_iyi_T_m, en_iyi_T_b = 0, 0.49, 0.51\n",
    "    for T_m_aday in esikler:\n",
    "        for T_b_aday in esikler:\n",
    "            tahminler = [2 if p[2] >= T_m_aday else 1 if p[1] >= T_b_aday else 0 for p in olasiliklar]\n",
    "            f1 = f1_score(y_test, tahminler, average='macro')\n",
    "            if f1 > en_iyi_f1:\n",
    "                en_iyi_f1, en_iyi_T_m, en_iyi_T_b = f1, T_m_aday, T_b_aday\n",
    "    nihai_tahminler = [2 if p[2] >= en_iyi_T_m else 1 if p[1] >= en_iyi_T_b else 0 for p in olasiliklar]\n",
    "    print()\n",
    "    print(\"-----------------RF_Results-----------------\")\n",
    "    print(f\"En iyi eşik sınırı: T_m={en_iyi_T_m:.2f}, T_b={en_iyi_T_b:.2f}\")\n",
    "    print(classification_report(y_test, nihai_tahminler, target_names=['normal','benign','cancer']))\n",
    "    print(confusion_matrix(y_test, nihai_tahminler))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, nihai_tahminler))\n",
    "    print(\"Precision:\", precision_score(y_test, nihai_tahminler, average='macro'))\n",
    "    print(\"Recall:\", recall_score(y_test, nihai_tahminler, average='macro'))\n",
    "    try:\n",
    "        print(\"AUC:\", roc_auc_score(pd.get_dummies(y_test), olasiliklar, average='macro', multi_class='ovr'))\n",
    "    except:\n",
    "        print(\"AUC hesaplanamadı (muhtemelen tek sınıf tahmini nedeniyle)\")\n",
    "\n",
    "    joblib.dump(model, \"RF_2_1.pkl\")\n",
    "    print(f\"Model kaydedildi:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365f4409",
   "metadata": {},
   "source": [
    "#### 📌 **HİPERPARAMETRELERİ BURADAN AYARLA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "173e2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4      \n",
    "xgb_n_estimators = 200\n",
    "xgb_max_depth = 20\n",
    "xgb_learning_rate = 0.1\n",
    "xgb_subsample = 0.72\n",
    "xgb_colsample_bytree = 0.8\n",
    "xgb_earlystop_rounds = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef11f9c",
   "metadata": {},
   "source": [
    "#### 🧠 **3. CNN Model Tanımı**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d75cf3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoost(X_tr, X_test, y_tr, y_test,X_feat,classes):\n",
    "    dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
    "    dtest  = xgb.DMatrix(X_test, label=y_test)\n",
    "    params = {\n",
    "        'objective':'multi:softprob',\n",
    "        'num_class':3,\n",
    "        'eta':xgb_learning_rate,\n",
    "        'max_depth':xgb_max_depth,\n",
    "        'subsample':xgb_subsample,\n",
    "        'colsample_bytree':xgb_colsample_bytree,\n",
    "        'eval_metric':'mlogloss'\n",
    "    }\n",
    "    model = xgb.train(params, dtrain, num_boost_round=xgb_n_estimators,\n",
    "                    early_stopping_rounds=xgb_earlystop_rounds,\n",
    "                    evals=[(dtest,'eval')], verbose_eval=False)\n",
    "\n",
    "    dtest_predict = xgb.DMatrix(X_test)\n",
    "    olasiliklar = model.predict(dtest_predict) # Corrected line: passing dtest_predict instead of X_test\n",
    "    esikler = np.linspace(0.4, 0.6, 21)\n",
    "    en_iyi_f1, en_iyi_T_m, en_iyi_T_b = 0, 0.48, 0.52\n",
    "    for T_m_aday in esikler:\n",
    "        for T_b_aday in esikler:\n",
    "            tahminler = [2 if p[2] >= T_m_aday else 1 if p[1] >= T_b_aday else 0 for p in olasiliklar]\n",
    "            f1 = f1_score(y_test, tahminler, average='macro')\n",
    "            if f1 > en_iyi_f1:\n",
    "                en_iyi_f1, en_iyi_T_m, en_iyi_T_b = f1, T_m_aday, T_b_aday\n",
    "    nihai_tahminler = [2 if p[2] >= en_iyi_T_m else 1 if p[1] >= en_iyi_T_b else 0 for p in olasiliklar]\n",
    "\n",
    "    print(\"------------XPBoost------------------\")\n",
    "    print(f\"En iyi eşik sınırı: T_m={en_iyi_T_m:.2f}, T_b={en_iyi_T_b:.2f}\")\n",
    "    print(classification_report(y_test, nihai_tahminler, target_names=['normal','benign','cancer']))\n",
    "    print(confusion_matrix(y_test, nihai_tahminler))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, nihai_tahminler))\n",
    "    print(\"Precision:\", precision_score(y_test, nihai_tahminler, average='macro'))\n",
    "    print(\"Recall:\", recall_score(y_test, nihai_tahminler, average='macro'))\n",
    "    try:\n",
    "        print(\"AUC:\", roc_auc_score(pd.get_dummies(y_test), olasiliklar, average='macro', multi_class='ovr'))\n",
    "    except:\n",
    "        print(\"AUC hesaplanamadı (muhtemelen tek sınıf tahmini nedeniyle)\")\n",
    "\n",
    "    model.save_model(f\"XGBoost_2_1.json\")\n",
    "    print(\"Model kaydedildi:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ff6069",
   "metadata": {},
   "source": [
    "#### 🧠 **3. CNN Model Tanımı**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b859467e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 24.1820 - accuracy: 0.5867 - val_loss: 8.8252 - val_accuracy: 0.7944\n",
      "Epoch 2/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 18.4141 - accuracy: 0.6475 - val_loss: 7.0956 - val_accuracy: 0.7944\n",
      "Epoch 3/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 15.0890 - accuracy: 0.6610 - val_loss: 7.0920 - val_accuracy: 0.7944\n",
      "Epoch 4/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 12.1941 - accuracy: 0.6537 - val_loss: 5.4501 - val_accuracy: 0.7944\n",
      "Epoch 5/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 12.0276 - accuracy: 0.6776 - val_loss: 3.9651 - val_accuracy: 0.7850\n",
      "Epoch 6/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 11.3750 - accuracy: 0.6610 - val_loss: 4.0162 - val_accuracy: 0.7944\n",
      "Epoch 7/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 9.4993 - accuracy: 0.6547 - val_loss: 3.6657 - val_accuracy: 0.7944\n",
      "Epoch 8/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 7.2470 - accuracy: 0.6578 - val_loss: 2.7465 - val_accuracy: 0.7944\n",
      "Epoch 9/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 7.8531 - accuracy: 0.6615 - val_loss: 2.3692 - val_accuracy: 0.7897\n",
      "Epoch 10/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 6.9268 - accuracy: 0.6537 - val_loss: 2.1440 - val_accuracy: 0.7944\n",
      "Epoch 11/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 6.9417 - accuracy: 0.6682 - val_loss: 1.8649 - val_accuracy: 0.7944\n",
      "Epoch 12/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 5.6844 - accuracy: 0.6573 - val_loss: 2.0673 - val_accuracy: 0.7944\n",
      "Epoch 13/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 4.2546 - accuracy: 0.6791 - val_loss: 1.8470 - val_accuracy: 0.7944\n",
      "Epoch 14/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 4.5692 - accuracy: 0.6874 - val_loss: 1.2741 - val_accuracy: 0.7944\n",
      "Epoch 15/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 3.5540 - accuracy: 0.6890 - val_loss: 1.3102 - val_accuracy: 0.7944\n",
      "Epoch 16/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 3.8370 - accuracy: 0.6822 - val_loss: 1.3321 - val_accuracy: 0.7944\n",
      "Epoch 17/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 3.5094 - accuracy: 0.6952 - val_loss: 1.3698 - val_accuracy: 0.7944\n",
      "Epoch 18/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 3.3818 - accuracy: 0.7072 - val_loss: 1.0707 - val_accuracy: 0.7944\n",
      "Epoch 19/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 2.9046 - accuracy: 0.7072 - val_loss: 1.0431 - val_accuracy: 0.7944\n",
      "Epoch 20/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 2.4690 - accuracy: 0.7066 - val_loss: 0.9210 - val_accuracy: 0.7944\n",
      "Epoch 21/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.1269 - accuracy: 0.7269 - val_loss: 0.8061 - val_accuracy: 0.7944\n",
      "Epoch 22/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 2.2250 - accuracy: 0.7103 - val_loss: 0.7235 - val_accuracy: 0.7944\n",
      "Epoch 23/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 2.0810 - accuracy: 0.7160 - val_loss: 0.7362 - val_accuracy: 0.7944\n",
      "Epoch 24/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 1.8478 - accuracy: 0.7321 - val_loss: 0.7077 - val_accuracy: 0.7944\n",
      "Epoch 25/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 1.7239 - accuracy: 0.7227 - val_loss: 0.7218 - val_accuracy: 0.7944\n",
      "Epoch 26/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 1.4326 - accuracy: 0.7212 - val_loss: 0.7380 - val_accuracy: 0.7944\n",
      "Epoch 27/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 1.2998 - accuracy: 0.7227 - val_loss: 0.7096 - val_accuracy: 0.7944\n",
      "Epoch 28/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 1.3061 - accuracy: 0.7150 - val_loss: 0.6501 - val_accuracy: 0.7944\n",
      "Epoch 29/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 1.1859 - accuracy: 0.7227 - val_loss: 0.7133 - val_accuracy: 0.7944\n",
      "Epoch 30/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 1.1568 - accuracy: 0.7321 - val_loss: 0.6222 - val_accuracy: 0.7944\n",
      "Epoch 31/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 1.0227 - accuracy: 0.7394 - val_loss: 0.6070 - val_accuracy: 0.7944\n",
      "Epoch 32/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.9284 - accuracy: 0.7435 - val_loss: 0.5939 - val_accuracy: 0.7944\n",
      "Epoch 33/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.8869 - accuracy: 0.7440 - val_loss: 0.6239 - val_accuracy: 0.7944\n",
      "Epoch 34/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.8013 - accuracy: 0.7555 - val_loss: 0.6129 - val_accuracy: 0.7944\n",
      "Epoch 35/40\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.7528 - accuracy: 0.7503 - val_loss: 0.6182 - val_accuracy: 0.7944\n",
      "Epoch 36/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.7641 - accuracy: 0.7617 - val_loss: 0.6126 - val_accuracy: 0.7944\n",
      "Epoch 37/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.7533 - accuracy: 0.7690 - val_loss: 0.6204 - val_accuracy: 0.7944\n",
      "Epoch 38/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.7553 - accuracy: 0.7664 - val_loss: 0.6209 - val_accuracy: 0.7944\n",
      "Epoch 39/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.7317 - accuracy: 0.7664 - val_loss: 0.6117 - val_accuracy: 0.7944\n",
      "Epoch 40/40\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.7210 - accuracy: 0.7726 - val_loss: 0.6165 - val_accuracy: 0.7944\n",
      "\n",
      "---------------------MLP_Results---------------------\n",
      "En iyi eşik sınırı: T_m=0.40, T_b=0.40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.79      1.00      0.88       187\n",
      "      benign       0.00      0.00      0.00        39\n",
      "      cancer       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.79       238\n",
      "   macro avg       0.26      0.33      0.29       238\n",
      "weighted avg       0.62      0.79      0.69       238\n",
      "\n",
      "[[187   0   0]\n",
      " [ 39   0   0]\n",
      " [ 12   0   0]]\n",
      "Accuracy: 0.7857142857142857\n",
      "Precision: 0.2619047619047619\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.5827454185742762\n",
      "Model kaydedildi: MLP_1_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dr.Ahmet\\anaconda3\\envs\\tf-gpu-211\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dr.Ahmet\\anaconda3\\envs\\tf-gpu-211\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dr.Ahmet\\anaconda3\\envs\\tf-gpu-211\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dr.Ahmet\\anaconda3\\envs\\tf-gpu-211\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    classes = ['normal','benign','cancer']\n",
    "    kok_dizin = os.path.join(os.getcwd(), \"Project2\")\n",
    "    X, y = extract_and_preprocess_parallel(kok_dizin, classes,n_jobs=-1)\n",
    "    X_feat, pca = extract_features(X)\n",
    "    X_tr, X_test, y_tr, y_test = train_test_split(X_feat, y, test_size=0.1,\n",
    "                                               stratify=y, random_state=42)\n",
    "    np.save(\"X_test_2_1.npy\", X_test)\n",
    "    np.save(\"y_test_2_1.npy\", y_test)\n",
    "    np.savez(\"X_feat_2_1.npz\", X_feat)\n",
    "    np.savez(\"X_pca_2_1.npz\", pca)\n",
    "    np.save(\"Xtr_preprocessed_2_1.npy\", X_tr)\n",
    "    np.save(\"ytr_preprocessed_2_1.npy\", y_tr)\n",
    "    \n",
    "    MLP(X_tr, X_test, y_tr, y_test,X_feat,classes)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a600216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------RF_Results-----------------\n",
      "En iyi eşik sınırı: T_m=0.55, T_b=0.40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.81      0.91      0.86       187\n",
      "      benign       0.33      0.23      0.27        39\n",
      "      cancer       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.76       238\n",
      "   macro avg       0.38      0.38      0.38       238\n",
      "weighted avg       0.69      0.76      0.72       238\n",
      "\n",
      "[[171  16   0]\n",
      " [ 30   9   0]\n",
      " [ 10   2   0]]\n",
      "Accuracy: 0.7563025210084033\n",
      "Precision: 0.38125329120589785\n",
      "Recall: 0.38173591114767585\n",
      "AUC: 0.6255389205703309\n",
      "Model kaydedildi:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dr.Ahmet\\anaconda3\\envs\\tf-gpu-211\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dr.Ahmet\\anaconda3\\envs\\tf-gpu-211\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dr.Ahmet\\anaconda3\\envs\\tf-gpu-211\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dr.Ahmet\\anaconda3\\envs\\tf-gpu-211\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Random_Forest(X_tr, X_test, y_tr, y_test,X_feat,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c4c142e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------XPBoost------------------\n",
      "En iyi eşik sınırı: T_m=0.40, T_b=0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.80      0.98      0.88       187\n",
      "      benign       0.62      0.13      0.21        39\n",
      "      cancer       1.00      0.08      0.15        12\n",
      "\n",
      "    accuracy                           0.80       238\n",
      "   macro avg       0.81      0.40      0.42       238\n",
      "weighted avg       0.78      0.80      0.74       238\n",
      "\n",
      "[[184   3   0]\n",
      " [ 34   5   0]\n",
      " [ 11   0   1]]\n",
      "Accuracy: 0.7983193277310925\n",
      "Precision: 0.8094978165938865\n",
      "Recall: 0.3984985602632661\n",
      "AUC: 0.5914411479726379\n",
      "Model kaydedildi:\n"
     ]
    }
   ],
   "source": [
    "XGBoost(X_tr, X_test, y_tr, y_test,X_feat,classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-211",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
