{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c01195bc",
   "metadata": {},
   "source": [
    "#### ðŸ“Œ **HÄ°PERPARAMETRELERÄ° BURADAN AYARLA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baa92a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3       \n",
    "batch_size = 32           \n",
    "pca_variance = 0.94       # PCA varyans koruma oranÄ±\n",
    "roi_crop_size = (256,256)\n",
    "patch_size = (128,128)\n",
    "mlp_hidden_units = [128, 528]\n",
    "mlp_dropout_rate = 0.5\n",
    "mlp_epochs = 40\n",
    "mlp_earlystop_patience = 25\n",
    "pixels_per_cell=(16,16)\n",
    "cells_per_block=(2,2)\n",
    "orientations=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c99ec62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, joblib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import hog, greycomatrix, greycoprops\n",
    "from skimage.filters import threshold_otsu, median\n",
    "from skimage.morphology import opening, disk\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from joblib import Parallel, delayed\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdac1a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_image(args):\n",
    "    img_path, label, classes = args\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, roi_crop_size)\n",
    "    img = img.astype(np.float32)\n",
    "\n",
    "    center = np.array(roi_crop_size) // 2\n",
    "    ps = np.array(patch_size) // 2\n",
    "    patch = img[center[0]-ps[0]:center[0]+ps[0], center[1]-ps[1]+0:center[1]+ps[1]]\n",
    "\n",
    "    patch = median(patch)\n",
    "    patch = cv2.GaussianBlur(patch, (3, 3), 0)\n",
    "    patch = patch.astype(np.float32) / 255.0\n",
    "\n",
    "    return patch, classes.index(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dff67e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_preprocess_parallel(root_dir, classes, n_jobs=-1):\n",
    "    class_dirs = {\n",
    "        'normal': ['Birad1'],\n",
    "        'benign': ['Birad3'],\n",
    "        'cancer': ['Birad4', 'Birad5'],\n",
    "    }\n",
    "    paths, labels = [], []\n",
    "    for cls, subdirs in class_dirs.items():\n",
    "        for sd in subdirs:\n",
    "            dir_path = os.path.join(root_dir, sd)\n",
    "            if not os.path.isdir(dir_path):\n",
    "                continue\n",
    "            for fname in sorted(os.listdir(dir_path)):\n",
    "                if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    paths.append(os.path.join(dir_path, fname))\n",
    "                    labels.append(cls)\n",
    "    \n",
    "\n",
    "    # === Paralel iÅŸleme ===\n",
    "    arg_list = [(img_path, lbl, classes) for img_path, lbl in zip(paths, labels)]\n",
    "    results = Parallel(n_jobs=n_jobs)(delayed(process_single_image)(args) for args in arg_list)\n",
    "\n",
    "    X, y = zip(*results)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26b0f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_image(im):\n",
    "    h = hog(im, pixels_per_cell=pixels_per_cell,\n",
    "                cells_per_block=cells_per_block,\n",
    "                orientations=orientations)\n",
    "    g = greycomatrix((im*255).astype(np.uint8), [1], [0], levels=256)\n",
    "    glcm = [greycoprops(g, prop)[0, 0] for prop in ('contrast', 'homogeneity', 'energy')]\n",
    "    area = np.sum(im > 0.5)\n",
    "    perimeter = np.sum(cv2.Canny((im * 255).astype(np.uint8), 50, 150) > 0)\n",
    "    ecc = 0\n",
    "    if area > 10:\n",
    "        pts = np.argwhere(im > 0.5)\n",
    "        rect = cv2.minAreaRect(pts.astype(np.float32))\n",
    "        ecc = rect[1][0] / (rect[1][1] + 1e-8)\n",
    "    return np.hstack([h, glcm, area, perimeter, ecc])\n",
    "\n",
    "def extract_features(X, out_prefix=None, n_jobs=-1):\n",
    "    # 2. UPDATE THE FUNCTION NAME INSIDE THE PARALLEL CALL HERE\n",
    "    feats = Parallel(n_jobs=n_jobs)(delayed(extract_features_from_image)(im) for im in X)\n",
    "    feats = np.array(feats)\n",
    "    pca = PCA(n_components=pca_variance)\n",
    "    X_feat = pca.fit_transform(feats)\n",
    "    return X_feat, pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b12eec",
   "metadata": {},
   "source": [
    " Metirkler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3c71fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --------------MLP RESULTS----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.33      1.00      0.50        20\n",
      "      benign       0.00      0.00      0.00        20\n",
      "      cancer       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.33        60\n",
      "   macro avg       0.11      0.33      0.17        60\n",
      "weighted avg       0.11      0.33      0.17        60\n",
      "\n",
      "Confusion Matrix:\n",
      " [[20  0  0]\n",
      " [20  0  0]\n",
      " [20  0  0]]\n",
      "Accuracy: 0.3333333333333333\n",
      "Precision: 0.1111111111111111\n",
      "Recall: 0.3333333333333333\n",
      "ðŸ“Œ F1 Score: 0.16666666666666666\n",
      "AUC: 0.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dr.Ahmet\\anaconda3\\envs\\tf-gpu-211\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dr.Ahmet\\anaconda3\\envs\\tf-gpu-211\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dr.Ahmet\\anaconda3\\envs\\tf-gpu-211\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dr.Ahmet\\anaconda3\\envs\\tf-gpu-211\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    classes = ['normal','benign','cancer']\n",
    "    kok_dizin = os.path.join(os.getcwd(), \"Project2\")\n",
    "    X_test, y_test = extract_and_preprocess_parallel(kok_dizin, classes,n_jobs=-1)\n",
    "    X_feat, pca = extract_features(X_test)\n",
    "    model = load_model(\"MLP_1_2.h5\")\n",
    "    T_m = 0.40\n",
    "    T_b = 0.40\n",
    "    probs = model.predict(X_feat)\n",
    "    preds = [2 if p[2] >= T_m else 1 if p[1] >= T_b else 0 for p in probs]\n",
    "    print(\"\\n --------------MLP RESULTS----------------\")\n",
    "    print(classification_report(y_test, preds, target_names=classes))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "    print(\"Precision:\", precision_score(y_test, preds, average='macro'))\n",
    "    print(\"Recall:\", recall_score(y_test, preds, average='macro'))\n",
    "    print(\"ðŸ“Œ F1 Score:\", f1_score(y_test, preds, average='macro'))\n",
    "    try:\n",
    "        print(\"AUC:\", roc_auc_score(pd.get_dummies(y_test), probs,\n",
    "                                 multi_class='ovr', average='macro'))\n",
    "    except:\n",
    "        print(\"AUC hesaplanamadÄ±.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0233bbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --------------RF RESULTS----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.31      0.80      0.44        20\n",
      "      benign       0.25      0.10      0.14        20\n",
      "      cancer       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.30        60\n",
      "   macro avg       0.19      0.30      0.20        60\n",
      "weighted avg       0.19      0.30      0.20        60\n",
      "\n",
      "Confusion Matrix:\n",
      " [[16  4  0]\n",
      " [18  2  0]\n",
      " [18  2  0]]\n",
      "Accuracy: 0.3\n",
      "Precision: 0.1858974358974359\n",
      "Recall: 0.3\n",
      "ðŸ“Œ F1 Score: 0.19576719576719578\n",
      "AUC: 0.4547916666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dr.Ahmet\\anaconda3\\envs\\tf-gpu-211\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dr.Ahmet\\anaconda3\\envs\\tf-gpu-211\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dr.Ahmet\\anaconda3\\envs\\tf-gpu-211\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dr.Ahmet\\anaconda3\\envs\\tf-gpu-211\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load(\"RF_2_1.pkl\")\n",
    "T_m = 0.55\n",
    "T_b = 0.40\n",
    "classes = ['normal', 'benign', 'cancer']\n",
    "label_map = {'normal': 0, 'benign': 1, 'cancer': 2}\n",
    "probs = model.predict_proba(X_feat) \n",
    "preds = [2 if p[2] >= T_m else 1 if p[1] >= T_b else 0 for p in probs]\n",
    "print(\"\\n --------------RF RESULTS----------------\")\n",
    "print(classification_report(y_test, preds, target_names=classes))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "print(\"Precision:\", precision_score(y_test, preds, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, preds, average='macro'))\n",
    "print(\"ðŸ“Œ F1 Score:\", f1_score(y_test, preds, average='macro'))\n",
    "try:\n",
    "    print(\"AUC:\", roc_auc_score(pd.get_dummies(y_test), probs,\n",
    "                                 multi_class='ovr', average='macro'))\n",
    "except:\n",
    "    print(\"AUC hesaplanamadÄ±.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0847c790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --------------XP-B RESULTS----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.37      1.00      0.54        20\n",
      "      benign       0.50      0.15      0.23        20\n",
      "      cancer       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.38        60\n",
      "   macro avg       0.29      0.38      0.26        60\n",
      "weighted avg       0.29      0.38      0.26        60\n",
      "\n",
      "Confusion Matrix:\n",
      " [[20  0  0]\n",
      " [17  3  0]\n",
      " [17  3  0]]\n",
      "Accuracy: 0.38333333333333336\n",
      "Precision: 0.29012345679012347\n",
      "Recall: 0.3833333333333333\n",
      "ðŸ“Œ F1 Score: 0.2571032571032571\n",
      "AUC: 0.6466666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dr.Ahmet\\anaconda3\\envs\\tf-gpu-211\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dr.Ahmet\\anaconda3\\envs\\tf-gpu-211\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dr.Ahmet\\anaconda3\\envs\\tf-gpu-211\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dr.Ahmet\\anaconda3\\envs\\tf-gpu-211\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "loaded_xgb_model_booster = xgb.Booster() \n",
    "loaded_xgb_model_booster.load_model(\"XGBoost_2_1.json\") \n",
    "classes = ['normal', 'benign', 'cancer']\n",
    "label_map = {'normal': 0, 'benign': 1, 'cancer': 2}\n",
    "\n",
    "\n",
    "dtest_predict = xgb.DMatrix(X_feat) \n",
    "probs = loaded_xgb_model_booster.predict(dtest_predict) \n",
    "preds = [2 if p[2] >= T_m else 1 if p[1] >= T_b else 0 for p in probs]\n",
    "T_m = 0.40\n",
    "T_b = 0.55\n",
    "\n",
    "print(\"\\n --------------XP-B RESULTS----------------\")\n",
    "print(classification_report(y_test, preds, target_names=classes))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "print(\"Precision:\", precision_score(y_test, preds, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, preds, average='macro'))\n",
    "print(\"ðŸ“Œ F1 Score:\", f1_score(y_test, preds, average='macro'))\n",
    "try:\n",
    "    print(\"AUC:\", roc_auc_score(pd.get_dummies(y_test), probs,\n",
    "                                 multi_class='ovr', average='macro'))\n",
    "except:\n",
    "    print(\"AUC hesaplanamadÄ±.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb2f8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-211",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
